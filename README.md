# RGBç›¸æœºå·¥ç¨‹å®è·µå®Œæ•´æŒ‡å—

<p align="center">
  <img src="docs/images/camera_pipeline.png" alt="ç›¸æœºå¤„ç†æµæ°´çº¿" width="800"/>
</p>

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®ç®€ä»‹](#é¡¹ç›®ç®€ä»‹)
- [ç¡¬ä»¶è¦æ±‚](#ç¡¬ä»¶è¦æ±‚)
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
  - [æ–¹å¼ä¸€: Dockeréƒ¨ç½²(æ¨è)](#æ–¹å¼ä¸€-dockeréƒ¨ç½²æ¨è)
  - [æ–¹å¼äºŒ: æœ¬åœ°ç¯å¢ƒé…ç½®](#æ–¹å¼äºŒ-æœ¬åœ°ç¯å¢ƒé…ç½®)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ¨¡å—è¯¦è§£](#æ¨¡å—è¯¦è§£)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [å‚è€ƒèµ„æ–™](#å‚è€ƒèµ„æ–™)

---

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æä¾›äººå½¢æœºå™¨äººRGBç›¸æœºæ„ŸçŸ¥çš„å®Œæ•´å·¥ç¨‹å®è·µ,æ¶µç›–ä»ç›¸æœºæ ‡å®šåˆ°æ·±åº¦å­¦ä¹ æ¨ç†çš„å…¨æµç¨‹ã€‚

**ä¸»è¦åŠŸèƒ½:**
- âœ… å¤šç§ç›¸æœºæ”¯æŒ(USB/CSI/RTSP)
- âœ… ç›¸æœºæ ‡å®šä¸ç•¸å˜æ ¡æ­£
- âœ… YOLOç‰©ä½“æ£€æµ‹ + TensorRTåŠ é€Ÿ
- âœ… äººä½“å§¿æ€ä¼°è®¡(MediaPipe)
- âœ… ROS2æ— ç¼é›†æˆ
- âœ… è§†è§‰ä¼ºæœåº”ç”¨ç¤ºä¾‹

**é€‚ç”¨å¹³å°:**
- x86_64 Linux (Ubuntu 20.04/22.04)
- NVIDIA Jetson (Nano/NX/AGX Orin)
- Raspberry Pi 4 (éƒ¨åˆ†åŠŸèƒ½)

---

## ç¡¬ä»¶è¦æ±‚

### æœ€ä½é…ç½®

| ç»„ä»¶ | è¦æ±‚ |
|-----|------|
| CPU | Intel i5 æˆ–åŒç­‰æ€§èƒ½ |
| å†…å­˜ | 8GB RAM |
| GPU | NVIDIA GPU (å¯é€‰,ç”¨äºåŠ é€Ÿ) |
| ç›¸æœº | USB 2.0ç›¸æœº æˆ– CSIç›¸æœº |
| å­˜å‚¨ | 20GB å¯ç”¨ç©ºé—´ |

### æ¨èé…ç½®(Jetsonå¹³å°)

| å‹å· | æ€§èƒ½ | é€‚ç”¨åœºæ™¯ |
|-----|------|---------|
| Jetson Nano | å…¥é—¨çº§ | å­¦ä¹ ã€åŸå‹éªŒè¯ |
| Jetson Xavier NX | ä¸­ç«¯ | å®æ—¶æ£€æµ‹ã€SLAM |
| Jetson AGX Orin | é«˜ç«¯ | å¤šç›¸æœºã€é«˜å¸§ç‡ |

### æ”¯æŒçš„ç›¸æœº

**USBç›¸æœº:**
- ç½—æŠ€ C920/C930e
- ä»»ä½•æ ‡å‡†UVCç›¸æœº

**å·¥ä¸šç›¸æœº:**
- Basler aceç³»åˆ—
- FLIR Blackfly

**æ·±åº¦ç›¸æœº:**
- Intel RealSense D435i
- Azure Kinect

**Jetson CSIç›¸æœº:**
- Raspberry Pi Camera Module V2
- IMX219/IMX477ä¼ æ„Ÿå™¨

---

## ç¯å¢ƒé…ç½®

### æ–¹å¼ä¸€: Dockeréƒ¨ç½²(æ¨è)

Dockeræ–¹å¼æä¾›å¼€ç®±å³ç”¨çš„ç¯å¢ƒ,é¿å…ä¾èµ–å†²çªã€‚

#### 1. å®‰è£…Docker

```bash
# Ubuntu/Debian
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER
newgrp docker

# Jetsonå¹³å°(ä½¿ç”¨NVIDIAå®˜æ–¹è„šæœ¬)
# å‚è€ƒ: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
```

#### 2. æ„å»ºDockeré•œåƒ

**x86å¹³å°:**

```bash
cd docker
docker build -f Dockerfile.x86 -t camera-perception:x86 .
```

**Jetsonå¹³å°:**

```bash
cd docker
docker build -f Dockerfile.jetson -t camera-perception:jetson .
```

#### 3. è¿è¡Œå®¹å™¨

**x86å¹³å°(å¸¦GPU):**

```bash
docker run --gpus all \
  --rm -it \
  --privileged \
  -v /dev:/dev \
  -v $PWD:/workspace \
  -e DISPLAY=$DISPLAY \
  -v /tmp/.X11-unix:/tmp/.X11-unix \
  --net=host \
  camera-perception:x86 \
  bash
```

**Jetsonå¹³å°:**

```bash
docker run --runtime nvidia \
  --rm -it \
  --privileged \
  -v /dev:/dev \
  -v $PWD:/workspace \
  -e DISPLAY=$DISPLAY \
  -v /tmp/.X11-unix:/tmp/.X11-unix \
  --net=host \
  camera-perception:jetson \
  bash
```

**Mac/Windowsç”¨æˆ·:**

ç”±äºç›¸æœºè®¿é—®é™åˆ¶,å»ºè®®ä½¿ç”¨è™šæ‹Ÿæœºæˆ–åŒç³»ç»Ÿã€‚

---

### æ–¹å¼äºŒ: æœ¬åœ°ç¯å¢ƒé…ç½®

#### 1. ç³»ç»Ÿè¦æ±‚

```bash
# æ£€æŸ¥ç³»ç»Ÿç‰ˆæœ¬
lsb_release -a

# æ”¯æŒ: Ubuntu 20.04/22.04
```

#### 2. å®‰è£…Pythonä¾èµ–

**åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ:**

```bash
# å®‰è£…venv
sudo apt-get update
sudo apt-get install python3-venv python3-dev

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# å‡çº§pip
pip install --upgrade pip
```

**å®‰è£…åŸºç¡€ä¾èµ–:**

```bash
pip install -r requirements.txt
```

**requirements.txt å†…å®¹:**

```txt
# åŸºç¡€åº“
numpy>=1.21.0
opencv-python>=4.5.0
opencv-contrib-python>=4.5.0
PyYAML>=5.4
Pillow>=8.0

# æ·±åº¦å­¦ä¹ 
torch>=1.10.0
torchvision>=0.11.0
onnx>=1.10.0
onnxruntime>=1.10.0  # CPUç‰ˆæœ¬
# onnxruntime-gpu>=1.10.0  # GPUç‰ˆæœ¬,ä¸ä¸Šé¢äºŒé€‰ä¸€

# å§¿æ€ä¼°è®¡
mediapipe>=0.8.9

# ROS2 (å¦‚æœä½¿ç”¨ROS2)
# ä¸é€šè¿‡pipå®‰è£…,ä½¿ç”¨aptå®‰è£…ROS2å,source setup.bash

# å·¥å…·
tqdm>=4.62.0
matplotlib>=3.4.0
```

**Jetsonå¹³å°ç‰¹æ®Šä¾èµ–:**

```bash
# TensorRT (Jetsonå·²é¢„è£…,åªéœ€Pythonç»‘å®š)
pip install pycuda

# Jetsonç‰¹å®šä¼˜åŒ–
pip install jetson-stats
```

#### 3. å®‰è£…OpenCV (å®Œæ•´ç‰ˆ)

ç³»ç»Ÿè‡ªå¸¦çš„OpenCVå¯èƒ½ç¼ºå°‘æŸäº›æ¨¡å—,æ¨èä»æºç ç¼–è¯‘:

```bash
cd scripts
bash setup_opencv.sh
```

**setup_opencv.sh å†…å®¹:**

```bash
#!/bin/bash
# OpenCVç¼–è¯‘è„šæœ¬ (æ”¯æŒCUDAã€GStreamer)

set -e

OPENCV_VERSION=4.8.0
BUILD_DIR=/tmp/opencv_build

echo "å¼€å§‹ç¼–è¯‘ OpenCV ${OPENCV_VERSION}..."

# å®‰è£…ä¾èµ–
sudo apt-get update
sudo apt-get install -y \
    build-essential cmake git pkg-config \
    libjpeg-dev libtiff-dev libpng-dev \
    libavcodec-dev libavformat-dev libswscale-dev libv4l-dev \
    libxvidcore-dev libx264-dev \
    libgtk-3-dev \
    libatlas-base-dev gfortran \
    python3-dev python3-numpy

# ä¸‹è½½æºç 
mkdir -p $BUILD_DIR && cd $BUILD_DIR
git clone --depth 1 --branch ${OPENCV_VERSION} https://github.com/opencv/opencv.git
git clone --depth 1 --branch ${OPENCV_VERSION} https://github.com/opencv/opencv_contrib.git

# åˆ›å»ºç¼–è¯‘ç›®å½•
cd opencv && mkdir build && cd build

# æ£€æµ‹CUDA
if command -v nvcc &> /dev/null; then
    CUDA_ARCH_BIN=""
    
    # æ£€æµ‹GPUæ¶æ„
    if lspci | grep -i nvidia | grep -qi "jetson"; then
        # Jetsonè®¾å¤‡
        if nvidia-smi | grep -qi "Orin"; then
            CUDA_ARCH_BIN="8.7"
        elif nvidia-smi | grep -qi "Xavier"; then
            CUDA_ARCH_BIN="7.2"
        else
            CUDA_ARCH_BIN="5.3"  # Nano
        fi
    else
        # æ¡Œé¢GPU,è‡ªåŠ¨æ£€æµ‹
        CUDA_ARCH_BIN="6.0,6.1,7.0,7.5,8.0,8.6"
    fi
    
    WITH_CUDA=ON
    echo "æ£€æµ‹åˆ°CUDA,æ¶æ„: ${CUDA_ARCH_BIN}"
else
    WITH_CUDA=OFF
    echo "æœªæ£€æµ‹åˆ°CUDA,å°†ç¼–è¯‘CPUç‰ˆæœ¬"
fi

# CMakeé…ç½®
cmake -D CMAKE_BUILD_TYPE=RELEASE \
    -D CMAKE_INSTALL_PREFIX=/usr/local \
    -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \
    -D OPENCV_ENABLE_NONFREE=ON \
    -D WITH_CUDA=${WITH_CUDA} \
    -D CUDA_ARCH_BIN="${CUDA_ARCH_BIN}" \
    -D WITH_CUDNN=ON \
    -D OPENCV_DNN_CUDA=ON \
    -D ENABLE_FAST_MATH=1 \
    -D CUDA_FAST_MATH=1 \
    -D WITH_CUBLAS=1 \
    -D WITH_GSTREAMER=ON \
    -D WITH_V4L=ON \
    -D WITH_QT=OFF \
    -D WITH_OPENGL=ON \
    -D BUILD_opencv_python3=ON \
    -D PYTHON3_EXECUTABLE=$(which python3) \
    -D PYTHON3_INCLUDE_DIR=$(python3 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())") \
    -D PYTHON3_PACKAGES_PATH=$(python3 -c "from distutils.sysconfig import get_python_lib; print(get_python_lib())") \
    -D BUILD_EXAMPLES=OFF \
    -D BUILD_TESTS=OFF \
    -D BUILD_PERF_TESTS=OFF \
    ..

# ç¼–è¯‘ (ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ)
NPROC=$(nproc)
echo "ä½¿ç”¨ ${NPROC} ä¸ªæ ¸å¿ƒç¼–è¯‘..."
make -j${NPROC}

# å®‰è£…
sudo make install
sudo ldconfig

# éªŒè¯
python3 -c "import cv2; print(f'OpenCV {cv2.__version__} å®‰è£…æˆåŠŸ')"
python3 -c "import cv2; print(f'CUDA: {cv2.cuda.getCudaEnabledDeviceCount() > 0}')"

echo "OpenCVç¼–è¯‘å®Œæˆ!"
```

**ä½¿ç”¨æ–¹æ³•:**

```bash
chmod +x scripts/setup_opencv.sh
./scripts/setup_opencv.sh

# ç¼–è¯‘æ—¶é—´: 
# - Jetson Nano: 2-3å°æ—¶
# - Jetson Xavier NX: 30-60åˆ†é’Ÿ  
# - x86 (8æ ¸): 15-30åˆ†é’Ÿ
```

#### 4. å®‰è£…TensorRT (Jetson)

Jetsonè®¾å¤‡å·²é¢„è£…TensorRT,åªéœ€å®‰è£…Pythonç»‘å®š:

```bash
# æŸ¥çœ‹TensorRTç‰ˆæœ¬
dpkg -l | grep TensorRT

# å®‰è£…Pythonç»‘å®š
pip install pycuda
```

**x86å¹³å°å®‰è£…TensorRT:**

```bash
cd scripts
bash setup_tensorrt.sh
```

**setup_tensorrt.sh å†…å®¹:**

```bash
#!/bin/bash
# TensorRTå®‰è£…è„šæœ¬ (x86å¹³å°)

set -e

TRT_VERSION=8.5.3.1
CUDA_VERSION=11.8

echo "å®‰è£… TensorRT ${TRT_VERSION}..."

# ä¸‹è½½TensorRT (éœ€è¦NVIDIAè´¦å·)
echo "è¯·ä»ä»¥ä¸‹é“¾æ¥ä¸‹è½½TensorRT:"
echo "https://developer.nvidia.com/nvidia-tensorrt-8x-download"
echo ""
echo "é€‰æ‹©: TensorRT ${TRT_VERSION} for Linux x86_64 and CUDA ${CUDA_VERSION}"
echo ""
read -p "ä¸‹è½½å®Œæˆå,è¾“å…¥tar.gzæ–‡ä»¶è·¯å¾„: " TRT_TAR

# è§£å‹
TRT_DIR=$(basename ${TRT_TAR} .tar.gz)
tar -xzf ${TRT_TAR}

# å®‰è£…
cd ${TRT_DIR}/python
pip install tensorrt-*-cp3*-none-linux_x86_64.whl

cd ../onnx_graphsurgeon
pip install onnx_graphsurgeon-*-py2.py3-none-any.whl

# è®¾ç½®ç¯å¢ƒå˜é‡
echo "export LD_LIBRARY_PATH=\$LD_LIBRARY_PATH:$(pwd)/../lib" >> ~/.bashrc
source ~/.bashrc

# éªŒè¯
python3 -c "import tensorrt; print(f'TensorRT {tensorrt.__version__} å®‰è£…æˆåŠŸ')"

echo "TensorRTå®‰è£…å®Œæˆ!"
```

#### 5. å®‰è£…ROS2 (å¯é€‰)

å¦‚æœéœ€è¦ROS2é›†æˆåŠŸèƒ½:

```bash
# Ubuntu 22.04 - ROS2 Humble
sudo apt update && sudo apt install -y curl gnupg lsb-release
curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key | sudo apt-key add -
sudo sh -c 'echo "deb http://packages.ros.org/ros2/ubuntu $(lsb_release -cs) main" > /etc/apt/sources.list.d/ros2-latest.list'
sudo apt update
sudo apt install -y ros-humble-desktop python3-colcon-common-extensions

# è®¾ç½®ç¯å¢ƒ
echo "source /opt/ros/humble/setup.bash" >> ~/.bashrc
source ~/.bashrc

# å®‰è£…visionç›¸å…³åŒ…
sudo apt install -y \
    ros-humble-cv-bridge \
    ros-humble-image-transport \
    ros-humble-compressed-image-transport \
    ros-humble-vision-msgs
```

**Ubuntu 20.04ç”¨æˆ·:**

```bash
# ä½¿ç”¨ROS2 Foxy
sudo apt install -y ros-foxy-desktop
```

#### 6. ç›¸æœºæƒé™é…ç½®

**USBç›¸æœºæƒé™:**

```bash
# æ·»åŠ ç”¨æˆ·åˆ°videoç»„
sudo usermod -aG video $USER

# åˆ›å»ºudevè§„åˆ™
sudo tee /etc/udev/rules.d/99-camera.rules > /dev/null <<EOF
SUBSYSTEM=="video4linux", GROUP="video", MODE="0660"
EOF

# é‡æ–°åŠ è½½è§„åˆ™
sudo udevadm control --reload-rules
sudo udevadm trigger

# é‡æ–°ç™»å½•ç”Ÿæ•ˆ
```

**CSIç›¸æœº(Jetson):**

```bash
# æ£€æŸ¥CSIç›¸æœºæ˜¯å¦è¢«è¯†åˆ«
ls -l /dev/video*

# æµ‹è¯•CSIç›¸æœº
gst-launch-1.0 nvarguscamerasrc ! 'video/x-raw(memory:NVMM),width=1920,height=1080' ! nvoverlaysink
```

---

## å¿«é€Ÿå¼€å§‹

### 1. æµ‹è¯•ç›¸æœºè¿æ¥

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ(å¦‚æœä½¿ç”¨)
source venv/bin/activate

# USBç›¸æœºæµ‹è¯•
python 01_camera_basics/camera_capture.py --source 0

# é¢„æœŸè¾“å‡º:
# ç›¸æœºå·²æ‰“å¼€:
#   åˆ†è¾¨ç‡: 640x480
#   å¸§ç‡: 30.0
# 
# æ“ä½œè¯´æ˜:
#   q - é€€å‡º
#   s - ä¿å­˜å½“å‰å¸§
#   f - æ˜¾ç¤º/éšè—å¸§ç‡
```

**å¸¸è§é—®é¢˜æ’æŸ¥:**

```bash
# 1. åˆ—å‡ºæ‰€æœ‰è§†é¢‘è®¾å¤‡
v4l2-ctl --list-devices

# 2. æŸ¥çœ‹ç›¸æœºæ”¯æŒçš„æ ¼å¼
v4l2-ctl -d /dev/video0 --list-formats-ext

# 3. æµ‹è¯•ç›¸æœº(ä½¿ç”¨ffplay)
ffplay /dev/video0
```

### 2. ç›¸æœºæ ‡å®š(5åˆ†é’Ÿå¿«é€Ÿæ ‡å®š)

**å‡†å¤‡å·¥ä½œ:**

1. æ‰“å°æ ‡å®šæ¿:ä½¿ç”¨`02_camera_calibration/generate_pattern.py`ç”Ÿæˆ

```bash
python 02_camera_calibration/generate_pattern.py \
    --type chessboard \
    --cols 9 \
    --rows 6 \
    --size 25 \
    --output calibration_board.pdf

# æ‰“å°åˆ°A4çº¸,æµ‹é‡å®é™…æ ¼å­å°ºå¯¸(åº”è¯¥æ˜¯25mm)
```

2. å›ºå®šæ ‡å®šæ¿:è´´åœ¨ç¡¬çº¸æ¿æˆ–äºšå…‹åŠ›æ¿ä¸Š,ä¿æŒå¹³æ•´

**æ ‡å®šæµç¨‹:**

```bash
# æ­¥éª¤1: é‡‡é›†å›¾åƒ(20-30å¼ )
python 02_camera_calibration/chessboard_calibration.py \
    --mode capture \
    --camera 0

# æ“ä½œ:
# - ç§»åŠ¨æ ‡å®šæ¿åˆ°ä¸åŒä½ç½®(å·¦/å³/ä¸Š/ä¸‹/ä¸­å¿ƒ)
# - æ—‹è½¬æ ‡å®šæ¿åˆ°ä¸åŒè§’åº¦(0Â°/30Â°/45Â°/60Â°)
# - æ”¹å˜æ ‡å®šæ¿è·ç¦»(è¿‘/ä¸­/è¿œ)
# - çœ‹åˆ°"Detected! Press 's' to save"æ—¶æŒ‰'s'ä¿å­˜
# - é‡‡é›†20-30å¼ åæŒ‰'q'é€€å‡º

# æ­¥éª¤2: æ‰§è¡Œæ ‡å®š
python 02_camera_calibration/chessboard_calibration.py \
    --mode calibrate \
    --images "calib_images/*.jpg" \
    --output camera_calib.yaml

# é¢„æœŸè¾“å‡º:
# æ ‡å®šæˆåŠŸ!
# é‡æŠ•å½±è¯¯å·®(RMS): 0.3521 åƒç´   # <0.5åƒç´ ä¸ºä¼˜ç§€
# 
# ç›¸æœºå†…å‚çŸ©é˜µ:
# [[635.2  0.0  318.4]
#  [  0.0 636.1 241.2]
#  [  0.0   0.0   1.0]]
# 
# è§†åœºè§’(FOV):
#   æ°´å¹³: 62.3Â°
#   å‚ç›´: 48.7Â°

# æ­¥éª¤3: æµ‹è¯•ç•¸å˜æ ¡æ­£
python 02_camera_calibration/chessboard_calibration.py \
    --mode test \
    --camera 0 \
    --output camera_calib.yaml

# è§‚å¯Ÿå·¦å³å¯¹æ¯”å›¾,ç›´çº¿åº”è¯¥å˜ç›´
```

**æ ‡å®šè´¨é‡è¯„ä¼°:**

| é‡æŠ•å½±è¯¯å·® | è´¨é‡ | è¯´æ˜ |
|----------|-----|------|
| < 0.3åƒç´  | ä¼˜ç§€ | å¯ç”¨äºç²¾å¯†æµ‹é‡ |
| 0.3-0.5åƒç´  | è‰¯å¥½ | é€‚åˆå¤§å¤šæ•°åº”ç”¨ |
| 0.5-1.0åƒç´  | å¯æ¥å— | ä¸€èˆ¬åº”ç”¨è¶³å¤Ÿ |
| > 1.0åƒç´  | è¾ƒå·® | éœ€é‡æ–°æ ‡å®š |

**æé«˜æ ‡å®šè´¨é‡çš„æŠ€å·§:**

- âœ… é‡‡é›†æ›´å¤šå›¾åƒ(30å¼ ä»¥ä¸Š)
- âœ… è¦†ç›–æ•´ä¸ªè§†é‡èŒƒå›´
- âœ… åŒ…å«å„ç§è§’åº¦å’Œè·ç¦»
- âœ… ä¿è¯æ ‡å®šæ¿å¹³æ•´
- âœ… å…‰ç…§å‡åŒ€,é¿å…è¿‡æ›å’Œé˜´å½±
- âŒ é¿å…æ¨¡ç³Šå›¾åƒ
- âŒ é¿å…æ ‡å®šæ¿å¡«æ»¡æ•´ä¸ªç”»é¢

### 3. ç‰©ä½“æ£€æµ‹ + TensorRTåŠ é€Ÿ

**å‡†å¤‡YOLOæ¨¡å‹:**

```bash
cd 04_object_detection/tensorrt_optimization

# æ­¥éª¤1: ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
wget https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt

# æ­¥éª¤2: å¯¼å‡ºONNX
python onnx_export.py \
    --weights yolov5s.pt \
    --img-size 640 \
    --batch-size 1 \
    --output yolov5s.onnx

# æ­¥éª¤3: æ„å»ºTensorRTå¼•æ“
python tensorrt_build.py \
    --onnx yolov5s.onnx \
    --engine yolov5s.engine \
    --precision fp16  # Jetsonä½¿ç”¨fp16, æ¡Œé¢GPUå¯ç”¨fp32

# æ„å»ºæ—¶é—´:
# - Jetson Nano: 5-10åˆ†é’Ÿ
# - Jetson Xavier NX: 2-3åˆ†é’Ÿ
# - RTX 3060: 30-60ç§’
```

**è¿è¡Œæ£€æµ‹:**

```bash
cd 04_object_detection

# å®æ—¶æ£€æµ‹
python yolo_tensorrt.py \
    --engine tensorrt_optimization/yolov5s.engine \
    --camera 0 \
    --conf 0.5

# é¢„æœŸæ€§èƒ½:
# - Jetson Nano: 10-15 FPS
# - Jetson Xavier NX: 30-40 FPS
# - Jetson AGX Orin: 60+ FPS
# - RTX 3060: 100+ FPS
```

**æ€§èƒ½å¯¹æ¯”:**

| å¹³å° | çº¯PyTorch | TensorRT | åŠ é€Ÿæ¯” |
|-----|----------|----------|--------|
| Jetson Nano | 3 FPS | 12 FPS | 4x |
| Jetson Xavier NX | 8 FPS | 35 FPS | 4.4x |
| RTX 3060 | 45 FPS | 120 FPS | 2.7x |

### 4. äººä½“å§¿æ€ä¼°è®¡

```bash
cd 05_pose_estimation

# MediaPipeå§¿æ€ä¼°è®¡
python mediapipe_pose.py --camera 0

# æ‰‹éƒ¨è¿½è¸ª
python hand_tracking.py --camera 0

# äººè„¸å…³é”®ç‚¹
python face_landmarks.py --camera 0
```

**MediaPipeæ€§èƒ½:**

- CPUæ¨¡å¼: 30-60 FPS (å–å†³äºCPUæ€§èƒ½)
- GPUåŠ é€Ÿ: 60+ FPS (éœ€è¦GPU)

### 5. ROS2é›†æˆ

```bash
# ç¡®ä¿å·²source ROS2ç¯å¢ƒ
source /opt/ros/humble/setup.bash

cd 06_ros2_integration

# å¯åŠ¨ç›¸æœºå‘å¸ƒèŠ‚ç‚¹
python camera_publisher.py \
    --camera 0 \
    --topic /camera/image_raw \
    --camera-info camera_calib.yaml

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æŸ¥çœ‹è¯é¢˜
ros2 topic list
ros2 topic hz /camera/image_raw
ros2 run rqt_image_view rqt_image_view
```

---

## æ¨¡å—è¯¦è§£

### æ¨¡å—1: ç›¸æœºåŸºç¡€æ“ä½œ

**æ–‡ä»¶:** `01_camera_basics/camera_capture.py`

**åŠŸèƒ½:**
- æ”¯æŒUSB/CSI/RTSPç›¸æœº
- åˆ†è¾¨ç‡å’Œå¸§ç‡è®¾ç½®
- å®æ—¶FPSæ˜¾ç¤º
- å›¾åƒä¿å­˜

**æ ¸å¿ƒä»£ç è§£æ:**

```python
# USBç›¸æœº
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

# Jetson CSIç›¸æœº (ä½¿ç”¨GStreamer)
gst_str = (
    f"nvarguscamerasrc ! "
    f"video/x-raw(memory:NVMM), width=1920, height=1080 ! "
    f"nvvidconv ! video/x-raw, format=BGRx ! "
    f"videoconvert ! video/x-raw, format=BGR ! appsink"
)
cap = cv2.VideoCapture(gst_str, cv2.CAP_GSTREAMER)
```

**æ€§èƒ½ä¼˜åŒ–æŠ€å·§:**

```python
# 1. ä½¿ç”¨ç¡¬ä»¶åŠ é€Ÿ (Jetson)
# åœ¨GStreamerç®¡é“ä¸­ä½¿ç”¨nvvidconv

# 2. å‡å°‘ä¸å¿…è¦çš„æ‹·è´
ret, frame = cap.read()  # ç›´æ¥ä½¿ç”¨,ä¸è¦æ‹·è´

# 3. é™ä½åˆ†è¾¨ç‡
# 640x480è¶³å¤Ÿå¤§å¤šæ•°åº”ç”¨,æ¯”1080på¿«4å€
```

---

### æ¨¡å—2: ç›¸æœºæ ‡å®š

**æ–‡ä»¶:** `02_camera_calibration/chessboard_calibration.py`

**åŸç†:**

ç›¸æœºæˆåƒæ¨¡å‹:
```
ä¸–ç•Œåæ ‡ç³» â†’ ç›¸æœºåæ ‡ç³» â†’ å›¾åƒåæ ‡ç³»

[u]   [fx  0  cx]   [X]
[v] = [ 0 fy cy] * [Y]
[1]   [ 0  0  1]   [Z]

å…¶ä¸­:
- (fx, fy): ç„¦è·(åƒç´ å•ä½)
- (cx, cy): ä¸»ç‚¹(å…‰è½´ä¸å›¾åƒå¹³é¢äº¤ç‚¹)
- (X, Y, Z): ç›¸æœºåæ ‡ç³»ä¸­çš„3Dç‚¹
- (u, v): å›¾åƒåƒç´ åæ ‡
```

**ç•¸å˜æ¨¡å‹:**

```
å¾„å‘ç•¸å˜: 
  x' = x(1 + k1*rÂ² + k2*râ´ + k3*râ¶)
  y' = y(1 + k1*rÂ² + k2*râ´ + k3*râ¶)

åˆ‡å‘ç•¸å˜:
  x' = x + 2p1*xy + p2(rÂ² + 2xÂ²)
  y' = y + p1(rÂ² + 2yÂ²) + 2p2*xy

å…¶ä¸­ rÂ² = xÂ² + yÂ²
```

**æ ‡å®šæ¿é€‰æ‹©:**

| ç±»å‹ | ä¼˜åŠ¿ | åŠ£åŠ¿ | é€‚ç”¨åœºæ™¯ |
|-----|------|------|---------|
| æ£‹ç›˜æ ¼ | ç²¾åº¦é«˜,æ˜“æ‰“å° | å¯¹ç§°æ€§æ˜“æ··æ·† | é€šç”¨æ ‡å®š |
| ChArUco | æŠ—é®æŒ¡,æ— æ­§ä¹‰ | éœ€è¦æ‰“å°ç²¾åº¦é«˜ | æ¨èä½¿ç”¨ |
| åœ†ç‚¹é˜µ | äºšåƒç´ ç²¾åº¦æœ€é«˜ | æ‰“å°è¦æ±‚é«˜ | é«˜ç²¾åº¦æµ‹é‡ |

---

### æ¨¡å—3: å›¾åƒå¤„ç†

**æ–‡ä»¶:** `03_image_processing/undistortion.py`

**ç•¸å˜æ ¡æ­£åŸç†:**

```python
# æ–¹æ³•1: ç›´æ¥æ ¡æ­£(æ…¢)
dst = cv2.undistort(src, camera_matrix, dist_coeffs)

# æ–¹æ³•2: æŸ¥æ‰¾è¡¨æ³•(å¿«,æ¨èå®æ—¶åº”ç”¨)
map1, map2 = cv2.initUndistortRectifyMap(
    camera_matrix, dist_coeffs, None, 
    new_camera_matrix, img_size, cv2.CV_16SC2
)
dst = cv2.remap(src, map1, map2, cv2.INTER_LINEAR)

# æ€§èƒ½å¯¹æ¯”:
# - undistort: æ¯å¸§é‡æ–°è®¡ç®—,çº¦8ms (640x480)
# - remap: ä½¿ç”¨é¢„è®¡ç®—æ˜ å°„è¡¨,çº¦2ms (640x480)
```

**è‡ªåŠ¨æ›å…‰ä¼˜åŒ–:**

```python
# æ–‡ä»¶: 03_image_processing/auto_exposure.py

# ç›´æ–¹å›¾å‡è¡¡åŒ–
def auto_exposure_histogram(image):
    # è½¬æ¢åˆ°YUVç©ºé—´
    yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
    # å¯¹Yé€šé“(äº®åº¦)è¿›è¡Œç›´æ–¹å›¾å‡è¡¡åŒ–
    yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])
    # è½¬å›BGR
    return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)

# CLAHE (å¯¹æ¯”åº¦å—é™çš„è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–)
def auto_exposure_clahe(image):
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    lab[:,:,0] = clahe.apply(lab[:,:,0])
    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
```

---

### æ¨¡å—4: YOLOæ£€æµ‹ + TensorRT

**æ–‡ä»¶:** `04_object_detection/yolo_tensorrt.py`

**TensorRTä¼˜åŒ–åŸç†:**

1. **ç®—å­èåˆ**: åˆå¹¶å¤šä¸ªå±‚å‡å°‘å†…å­˜è®¿é—®
2. **ç²¾åº¦æ ¡å‡†**: FP16/INT8é‡åŒ–
3. **å†…æ ¸è°ƒä¼˜**: ä¸ºç‰¹å®šç¡¬ä»¶é€‰æ‹©æœ€ä¼˜kernel

**æ¨¡å‹è½¬æ¢æµç¨‹:**

```
PyTorch (.pt) 
    â†“ [export]
ONNX (.onnx)
    â†“ [build engine]
TensorRT (.engine)
    â†“ [inference]
ç»“æœ
```

**ç²¾åº¦é€‰æ‹©:**

| ç²¾åº¦ | é€Ÿåº¦ | ç²¾åº¦æŸå¤± | é€‚ç”¨å¹³å° |
|-----|------|---------|---------|
| FP32 | åŸºå‡† | 0% | æ¡Œé¢GPU |
| FP16 | 2x | <1% | Jetson,ç°ä»£GPU |
| INT8 | 4x | 1-3% | éœ€è¦æ ¡å‡†æ•°æ®é›† |

**INT8é‡åŒ–ç¤ºä¾‹:**

```python
# æ–‡ä»¶: 04_object_detection/tensorrt_optimization/tensorrt_build.py

def build_engine_int8(onnx_path, calib_dataset):
    # åˆ›å»ºæ ¡å‡†å™¨
    calibrator = Int8Calibrator(calib_dataset)
    
    config.set_flag(trt.BuilderFlag.INT8)
    config.int8_calibrator = calibrator
    
    # æ„å»ºå¼•æ“
    engine = builder.build_engine(network, config)
    return engine
```

---

### æ¨¡å—5: å§¿æ€ä¼°è®¡

**æ–‡ä»¶:** `05_pose_estimation/mediapipe_pose.py`

**MediaPipe Poseå…³é”®ç‚¹:**

```
0: nose (é¼»å­)
1-2: left/right eye (å·¦å³çœ¼)
3-4: left/right ear (å·¦å³è€³)
5-6: left/right shoulder (å·¦å³è‚©)
7-8: left/right elbow (å·¦å³è‚˜)
9-10: left/right wrist (å·¦å³è…•)
11-12: left/right hip (å·¦å³é«‹)
13-14: left/right knee (å·¦å³è†)
15-16: left/right ankle (å·¦å³è¸)
```

**åº”ç”¨ç¤ºä¾‹: è·Œå€’æ£€æµ‹**

```python
def detect_fall(landmarks):
    """
    ç®€å•çš„è·Œå€’æ£€æµ‹ç®—æ³•
    åˆ¤æ–­ä¾æ®: èº¯å¹²è§’åº¦
    """
    # è·å–å…³é”®ç‚¹
    shoulder = landmarks[5]  # å·¦è‚©
    hip = landmarks[11]      # å·¦é«‹
    
    # è®¡ç®—èº¯å¹²è§’åº¦
    angle = np.arctan2(hip.y - shoulder.y, 
                      hip.x - shoulder.x)
    angle_deg = np.degrees(angle)
    
    # èº¯å¹²æ¥è¿‘æ°´å¹³ â†’ å¯èƒ½è·Œå€’
    if abs(angle_deg) < 30:  # èº¯å¹²ä¸æ°´å¹³å¤¹è§’<30Â°
        return True
    return False
```

---

### æ¨¡å—6: ROS2é›†æˆ

**æ–‡ä»¶:** `06_ros2_integration/camera_publisher.py`

**ROS2ç›¸æœºå‘å¸ƒèŠ‚ç‚¹:**

```python
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge

class CameraPublisher(Node):
    def __init__(self):
        super().__init__('camera_publisher')
        
        # åˆ›å»ºå‘å¸ƒè€…
        self.image_pub = self.create_publisher(
            Image, '/camera/image_raw', 10)
        self.info_pub = self.create_publisher(
            CameraInfo, '/camera/camera_info', 10)
        
        # CV Bridge
        self.bridge = CvBridge()
        
        # å®šæ—¶å™¨(30Hz)
        self.timer = self.create_timer(1.0/30.0, self.timer_callback)
        
        # æ‰“å¼€ç›¸æœº
        self.cap = cv2.VideoCapture(0)
    
    def timer_callback(self):
        ret, frame = self.cap.read()
        if ret:
            # è½¬æ¢ä¸ºROS Imageæ¶ˆæ¯
            msg = self.bridge.cv2_to_imgmsg(frame, 'bgr8')
            msg.header.stamp = self.get_clock().now().to_msg()
            msg.header.frame_id = 'camera'
            
            # å‘å¸ƒ
            self.image_pub.publish(msg)
```

**Launchæ–‡ä»¶ç¤ºä¾‹:**

```python
# 06_ros2_integration/launch/camera.launch.py

from launch import LaunchDescription
from launch_ros.actions import Node

def generate_launch_description():
    return LaunchDescription([
        Node(
            package='camera_perception',
            executable='camera_publisher',
            name='camera',
            parameters=[
                {'camera_id': 0},
                {'frame_rate': 30},
                {'image_width': 640},
                {'image_height': 480}
            ]
        ),
        Node(
            package='image_proc',
            executable='image_proc',
            name='image_proc',
            remappings=[
                ('image', '/camera/image_raw')
            ]
        )
    ])
```

---

## æ€§èƒ½ä¼˜åŒ–

### 1. å‡å°‘å»¶è¿Ÿ

**ç›¸æœºé…ç½®:**

```python
# å‡å°‘ç¼“å†²åŒº(é™ä½å»¶è¿Ÿä½†å¯èƒ½ä¸¢å¸§)
cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

# ç¦ç”¨è‡ªåŠ¨å¯¹ç„¦(é¿å…å¯¹ç„¦å»¶è¿Ÿ)
cap.set(cv2.CAP_PROP_AUTOFOCUS, 0)
cap.set(cv2.CAP_PROP_FOCUS, 30)  # æ‰‹åŠ¨å¯¹ç„¦å€¼

# ç¦ç”¨è‡ªåŠ¨æ›å…‰
cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)  # æ‰‹åŠ¨æ¨¡å¼
cap.set(cv2.CAP_PROP_EXPOSURE, -5)  # æ›å…‰å€¼
```

**å¤šçº¿ç¨‹æ•è·:**

```python
import threading
from queue import Queue

class CameraThread(threading.Thread):
    def __init__(self, camera_id):
        super().__init__()
        self.cap = cv2.VideoCapture(camera_id)
        self.queue = Queue(maxsize=1)
        self.running = True
    
    def run(self):
        while self.running:
            ret, frame = self.cap.read()
            if not self.queue.full():
                self.queue.put(frame)
    
    def read(self):
        return self.queue.get()
```

### 2. æé«˜å¸§ç‡

**é™ä½åˆ†è¾¨ç‡:**

```python
# 640x480 vs 1920x1080
# - åƒç´ æ•°å°‘9å€
# - å¤„ç†é€Ÿåº¦æå‡çº¦9å€
# - ä¼ è¾“å¸¦å®½å°‘9å€
```

**ç¡¬ä»¶åŠ é€Ÿ(Jetson):**

```python
# ä½¿ç”¨NVMM(é›¶æ‹·è´)
gst_str = (
    "nvarguscamerasrc ! "
    "video/x-raw(memory:NVMM), width=1920, height=1080 ! "
    "nvvidconv ! video/x-raw, format=BGRx ! "
    "videoconvert ! appsink"
)
```

**ä½¿ç”¨GPUåŠ é€ŸOpenCV:**

```python
# ä¸Šä¼ åˆ°GPU
gpu_frame = cv2.cuda_GpuMat()
gpu_frame.upload(frame)

# GPUä¸Šå¤„ç†
gpu_gray = cv2.cuda.cvtColor(gpu_frame, cv2.COLOR_BGR2GRAY)
gpu_blur = cv2.cuda.GaussianBlur(gpu_gray, (5,5), 0)

# ä¸‹è½½å›CPU
result = gpu_blur.download()
```

### 3. é™ä½åŠŸè€—(Jetson)

```bash
# æŸ¥çœ‹å½“å‰æ¨¡å¼
sudo nvpmodel -q

# è®¾ç½®ä¸ºçœç”µæ¨¡å¼
sudo nvpmodel -m 1

# é™åˆ¶æœ€å¤§åŠŸç‡(ä¾‹å¦‚10W)
sudo nvpmodel -m 0
sudo jetson_clocks --show
```

**ä»£ç å±‚é¢ä¼˜åŒ–:**

```python
# åŠ¨æ€è°ƒæ•´å¤„ç†é¢‘ç‡
def adaptive_processing(frame, fps_target=30):
    # åªåœ¨å¸§ç‡ä½äºç›®æ ‡æ—¶è·³è¿‡å¤„ç†
    if current_fps < fps_target:
        return None  # è·³è¿‡è¿™ä¸€å¸§
    else:
        return process_frame(frame)
```

---

## å¸¸è§é—®é¢˜

### Q1: ç›¸æœºæ— æ³•æ‰“å¼€

**ç—‡çŠ¶:**
```
cv2.error: (-215) !_src.empty() in function 'cvtColor'
```

**æ’æŸ¥æ­¥éª¤:**

```bash
# 1. æ£€æŸ¥è®¾å¤‡æ˜¯å¦å­˜åœ¨
ls -l /dev/video*

# 2. æ£€æŸ¥æƒé™
sudo chmod 666 /dev/video0

# 3. æ£€æŸ¥æ˜¯å¦è¢«å ç”¨
lsof /dev/video0

# 4. æµ‹è¯•åŸºç¡€æ•è·
ffmpeg -f v4l2 -i /dev/video0 -frames 1 test.jpg
```

**è§£å†³æ–¹æ¡ˆ:**

```python
# å°è¯•ä¸åŒçš„backend
cap = cv2.VideoCapture(0, cv2.CAP_V4L2)  # Linux
cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # Windows
cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)  # macOS
```

---

### Q2: æ ‡å®šé‡æŠ•å½±è¯¯å·®è¿‡å¤§

**åŸå› :**
- æ ‡å®šæ¿ä¸å¹³æ•´
- é‡‡é›†å›¾åƒæ¨¡ç³Š
- æ ‡å®šæ¿è§’åº¦èŒƒå›´ä¸å¤Ÿ
- å›¾åƒæ•°é‡å¤ªå°‘

**è§£å†³:**

```bash
# 1. æ£€æŸ¥æ ‡å®šå›¾åƒè´¨é‡
python scripts/check_calibration_quality.py --images "calib_images/*.jpg"

# 2. é‡æ–°é‡‡é›†
# - è‡³å°‘20å¼ å›¾åƒ
# - è¦†ç›–ç”»é¢çš„ä¸­å¿ƒã€å››è§’ã€è¾¹ç¼˜
# - åŒ…å«è¿‘è·ç¦»(30cm)å’Œè¿œè·ç¦»(2m)
# - æ—‹è½¬è§’åº¦: 0Â°, 30Â°, 45Â°, 60Â°

# 3. ä½¿ç”¨ChArUcoæ¿(æ›´é²æ£’)
python 02_camera_calibration/charuco_calibration.py
```

---

### Q3: TensorRTå¼•æ“æ„å»ºå¤±è´¥

**ç—‡çŠ¶:**
```
[TensorRT] ERROR: engine.cpp (1047) - Serialization Error in validate: 0
```

**åŸå› :**
- ONNXæ¨¡å‹ä¸å…¼å®¹
- TensorRTç‰ˆæœ¬ä¸åŒ¹é…
- ç®—å­ä¸æ”¯æŒ

**è§£å†³:**

```bash
# 1. æ£€æŸ¥ONNXæ¨¡å‹
python -c "import onnx; model = onnx.load('model.onnx'); onnx.checker.check_model(model)"

# 2. ç®€åŒ–æ¨¡å‹
python -m onnxsim model.onnx model_sim.onnx

# 3. ä½¿ç”¨å…¼å®¹çš„ç‰ˆæœ¬
# PyTorch 1.12 + TensorRT 8.5 (Jetson)
# PyTorch 2.0 + TensorRT 8.6 (Desktop)

# 4. é€å±‚æ£€æŸ¥
trtexec --onnx=model.onnx --verbose
```

---

### Q4: ROS2å›¾åƒä¼ è¾“å»¶è¿Ÿé«˜

**åŸå› :**
- ä½¿ç”¨æœªå‹ç¼©å›¾åƒä¼ è¾“
- ç½‘ç»œå¸¦å®½ä¸è¶³
- QoSè®¾ç½®ä¸å½“

**è§£å†³:**

```python
# 1. ä½¿ç”¨å‹ç¼©å›¾åƒä¼ è¾“
from sensor_msgs.msg import CompressedImage

# å‘å¸ƒå‹ç¼©å›¾åƒ
compressed_msg = self.bridge.cv2_to_compressed_imgmsg(frame, dst_format='jpg')
self.pub.publish(compressed_msg)

# 2. è°ƒæ•´QoS
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy

qos = QoSProfile(
    reliability=ReliabilityPolicy.BEST_EFFORT,  # å…è®¸ä¸¢åŒ…
    history=HistoryPolicy.KEEP_LAST,
    depth=1  # åªä¿ç•™æœ€æ–°ä¸€å¸§
)

self.pub = self.create_publisher(Image, '/camera/image', qos)

# 3. é™ä½åˆ†è¾¨ç‡æˆ–å¸§ç‡
```

---

### Q5: Jetsonè¿è¡Œç¼“æ…¢

**æ’æŸ¥:**

```bash
# 1. æ£€æŸ¥å½“å‰çŠ¶æ€
jtop  # æŸ¥çœ‹CPU/GPU/å†…å­˜ä½¿ç”¨ç‡

# 2. æ£€æŸ¥æ¸©åº¦
cat /sys/devices/virtual/thermal/thermal_zone*/temp

# 3. æ£€æŸ¥ç”µæºæ¨¡å¼
sudo nvpmodel -q

# 4. æ£€æŸ¥æ˜¯å¦é™é¢‘
cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_cur_freq
```

**ä¼˜åŒ–:**

```bash
# 1. æœ€å¤§æ€§èƒ½æ¨¡å¼
sudo nvpmodel -m 0
sudo jetson_clocks

# 2. å…³é—­å›¾å½¢ç•Œé¢(å‘½ä»¤è¡Œæ¨¡å¼)
sudo systemctl set-default multi-user.target
sudo reboot

# 3. å¢åŠ swap(å¦‚æœå†…å­˜ä¸è¶³)
sudo fallocate -l 4G /var/swapfile
sudo chmod 600 /var/swapfile
sudo mkswap /var/swapfile
sudo swapon /var/swapfile
```

---

### Q6: MediaPipeåœ¨Jetsonä¸Šæ— æ³•å®‰è£…

**é—®é¢˜:**
```
ERROR: Could not find a version that satisfies the requirement mediapipe
```

**è§£å†³:**

```bash
# æ–¹æ³•1: ä½¿ç”¨é¢„ç¼–è¯‘wheel (æ¨è)
wget https://github.com/PINTO0309/mediapipe-bin/releases/download/v0.8.11/mediapipe-0.8.11_cuda11.4-cp38-cp38-linux_aarch64.whl
pip install mediapipe-0.8.11_cuda11.4-cp38-cp38-linux_aarch64.whl

# æ–¹æ³•2: ä»æºç ç¼–è¯‘ (è€—æ—¶2-3å°æ—¶)
git clone https://github.com/google/mediapipe.git
cd mediapipe
# å‚è€ƒå®˜æ–¹æ–‡æ¡£ç¼–è¯‘
```

---

## Dockeré•œåƒé…ç½®

**Dockerfile.x86:**

```dockerfile
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04

# é¿å…äº¤äº’å¼æç¤º
ENV DEBIAN_FRONTEND=noninteractive

# å®‰è£…åŸºç¡€ä¾èµ–
RUN apt-get update && apt-get install -y \
    python3-pip \
    python3-dev \
    libopencv-dev \
    python3-opencv \
    libgstreamer1.0-dev \
    libgstreamer-plugins-base1.0-dev \
    v4l-utils \
    wget \
    git \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt /tmp/
RUN pip3 install --no-cache-dir -r /tmp/requirements.txt

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /workspace

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/workspace
ENV DISPLAY=:0

CMD ["/bin/bash"]
```

**Dockerfile.jetson:**

```dockerfile
FROM nvcr.io/nvidia/l4t-pytorch:r35.2.1-pth2.0-py3

# å®‰è£…é¢å¤–ä¾èµ–
RUN apt-get update && apt-get install -y \
    python3-opencv \
    libopencv-dev \
    v4l-utils \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…PythonåŒ…
RUN pip3 install --no-cache-dir \
    pycuda \
    mediapipe \
    PyYAML \
    tqdm

WORKDIR /workspace

CMD ["/bin/bash"]
```

**æ„å»ºå’Œä½¿ç”¨:**

```bash
# æ„å»º
docker build -f docker/Dockerfile.x86 -t camera-perception:x86 .

# è¿è¡Œ(å¯ç”¨ç›¸æœºå’Œæ˜¾ç¤º)
docker run --rm -it \
    --gpus all \
    --privileged \
    -v /dev:/dev \
    -v $PWD:/workspace \
    -e DISPLAY=$DISPLAY \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    --net=host \
    camera-perception:x86
```

---

## æ€§èƒ½åŸºå‡†æµ‹è¯•

ä½¿ç”¨æä¾›çš„åŸºå‡†æµ‹è¯•è„šæœ¬:

```bash
python scripts/benchmark.py --all

# è¾“å‡ºç¤ºä¾‹:
# ========== æ€§èƒ½åŸºå‡†æµ‹è¯• ==========
# å¹³å°: Jetson Xavier NX
# 
# 1. ç›¸æœºæ•è· (640x480@30fps)
#    - å¹³å‡å»¶è¿Ÿ: 33.2ms
#    - ç¨³å®šæ€§: 99.2%
# 
# 2. ç•¸å˜æ ¡æ­£
#    - å¹³å‡è€—æ—¶: 2.1ms
#    - ååé‡: 476 fps
# 
# 3. YOLOæ£€æµ‹ (TensorRT FP16)
#    - å¹³å‡è€—æ—¶: 28.5ms
#    - ååé‡: 35 fps
# 
# 4. å§¿æ€ä¼°è®¡ (MediaPipe)
#    - å¹³å‡è€—æ—¶: 16.3ms
#    - ååé‡: 61 fps
```

---

## å‚è€ƒèµ„æ–™

**å®˜æ–¹æ–‡æ¡£:**
- [OpenCV Documentation](https://docs.opencv.org/)
- [TensorRT Developer Guide](https://docs.nvidia.com/deeplearning/tensorrt/)
- [MediaPipe](https://google.github.io/mediapipe/)
- [ROS2 Documentation](https://docs.ros.org/en/humble/)

**æ¨èé˜…è¯»:**
- Zhang, Z. "A flexible new technique for camera calibration." (2000)
- Redmon, J. "YOLOv3: An Incremental Improvement." (2018)

**è§†é¢‘æ•™ç¨‹:**
- [ç›¸æœºæ ‡å®šåŸç†](https://www.youtube.com/watch?v=...)
- [TensorRTä¼˜åŒ–å®æˆ˜](https://www.youtube.com/watch?v=...)

**ç¤¾åŒºèµ„æº:**
- [OpenCVè®ºå›](https://forum.opencv.org/)
- [NVIDIAå¼€å‘è€…è®ºå›](https://forums.developer.nvidia.com/)
- [ROS Answers](https://answers.ros.org/)

---

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Request!

**å¼€å‘ç¯å¢ƒè®¾ç½®:**

```bash
# Forkå¹¶å…‹éš†ä»“åº“
git clone https://github.com/8866lt/camera-perception.git
cd camera-perception

# åˆ›å»ºåˆ†æ”¯
git checkout -b feature/your-feature

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt

# è¿è¡Œæµ‹è¯•
pytest tests/

# æäº¤ä»£ç 
git commit -am "Add your feature"
git push origin feature/your-feature
```

---

## è”ç³»æ–¹å¼

- GitHub: [(https://github.com/8866lt)]
- çŸ¥ä¹: [https://www.zhihu.com/people/su-xin-ran-64-35)]
- Email: [hehuaizhou@foxmail.com]

---

**æœ€åæ›´æ–°:** 2025å¹´12æœˆ

**ç‰ˆæœ¬:** v1.0.0


